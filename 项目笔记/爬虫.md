# 爬虫 & 搜索算法



**网络爬虫的整体执行流程：**

1） 确定一个（多个）种子网页

2） 进行数据的内容提取

3） 将网页中的关联网页连接提取出来

4） 将尚未爬取的关联网页内容放到一个队列中

5） 从队列中取出一个待爬取的页面，判断之前是否爬过。

6） 把没有爬过的进行爬取，并进行之前的重复操作。

7） 直到队列中没有新的内容，爬虫执行结束。

### 概念:



1） 深度（depth）：一般来说，表示从种子页到当前页的打开连接数，一般建议不要超过5层。

2） 广度优先 (Breadth-First Search)和深度优先：表示爬取时的优先级。建议使用广度优先，按深度的层级来顺序爬取。

### 广度优先算法（Breadth-First Search）

BFS是从根节点开始，沿着树的宽度遍历树的节点，如果发现目标，则演算终止。

广度优先搜索的实现一般采用open-closed表。

> 从算法的观点，所有因为展开节点而得到的子节点都会被加进一个先进先出的队列中。

> 实践中，其邻居节点未检节点会被放置在一个称为*open*的容器中（如队列或是[链表](https://baike.baidu.com/item/链表)），

> 而被检验过的节点则被放置在被称为*closed*的容器中。（open-closed表）

所谓广度，就是**一层一层的，向下遍历，层层堵截**

![img](https://gss0.bdstatic.com/-4o3dSag_xI4khGkpoWK1HF6hhy/baike/s%3D220/sign=78878a689bdda144de096bb082b6d009/e1fe9925bc315c6040f8459481b1cb134954775f.jpg)

结果是V1 V2 V3 V4 V5 V6 V7 V8

### 空间复杂度

因为所有节点都必须被储存，因此BFS的[空间复杂度](https://baike.baidu.com/item/空间复杂度)为 O(|V| + |E|)

其中 |V| 是节点的数目，而 |E| 是图中边的数目。

另一种说法称BFS的空间复杂度为*O*(*B^M*)，其中 B 是最大分支系数，而 M 是树的最长路径长度。

### 时间复杂度

BFS必须寻找所有到可能节点的所有路径，因此其[时间复杂度](https://baike.baidu.com/item/时间复杂度/1894057)为 O(|V| + |E|)，

其中 |V| 是节点的数目，而 |E| 是图中边的数目。

### 完全性

广度优先搜索算法具有完全性。这意指无论图形的种类如何，只要目标存在，则BFS一定会找到。

然而，若目标不存在，且图为无限大，则BFS将不收敛（不会结束）。

### 最佳解

若所有边的长度相等，广度优先搜索算法是最佳解 

亦即它找到的第一个解，距离根节点的边数目一定最少



```java

public class BFS {
    
    	public static void main(String[] args){
    		//初始化先建立起各个节点信息，以及对应的直接子节点列表
    		HashMap<String,String[]> map = new HashMap<>();
    		map.put("A", new String[] {"B","C"});
    		map.put("B", new String[] {"E"});
    		map.put("C", new String[] {"D","F"});
    		map.put("D", new String[] {"E"});
    		map.put("E", new String[] {"H"});
    		map.put("F", new String[] {"E","G"});
    		map.put("G", new String[] {"H"});
    		map.put("H", new String[] {});
    		//获取从A到H的最短路径节点链表
    		Node target = findTarget("A","H",map);
    		//打印出最短路径的各个节点信息
    		printSearPath(target);
    
    	}
    
    	/**
    	 * 打印出到达节点target所经过的各个节点信息
    	 * @param target
    	 */
    	static void printSearPath(Node target) {
    		if (target != null) {
    			System.out.print("找到了目标节点:" + target.id + "\n");
    			
    			List<Node> searchPath = new ArrayList<Node>();
    			searchPath.add(target);
    			Node node = target.parent;
    			while(node!=null) {
    				searchPath.add(node);
    				node = node.parent;
    			}
    			String path = "";
    			for(int i=searchPath.size()-1;i>=0;i--) {
    				path += searchPath.get(i).id;
    				if(i!=0) {
    					path += "-->";
    				}
    			}
    			System.out.print("步数最短："+path);
    		} else {
    			System.out.print("未找到了目标节点");
    		}
    	}
    	
    	/**
    	 * 从指定的开始节点 startId ，查询到目标节点targetId 的最短路径
    	 * @param startId
    	 * @param targetId
    	 * @param map
    	 * @return
    	 */
    	static Node findTarget(String startId,String targetId,HashMap<String,String[]> map) {
    		List<String> hasSearchList = new ArrayList<String>();
    		LinkedList<Node> queue = new LinkedList<Node>();
    		queue.offer(new Node(startId,null));
    		while(!queue.isEmpty()) {
    			Node node = queue.poll();
    			
    			if(hasSearchList.contains(node.id)) {
    				//跳过已经搜索过的，避免重复或者死循环
    				continue;
    			}
    			System.out.print("判断节点:" + node.id +"\n");
    			if (targetId.equals(node.id)) {
    				return node;
    			}
    			hasSearchList.add(node.id);
    			if (map.get(node.id) != null && map.get(node.id).length > 0) {
    				for (String childId : map.get(node.id)) {
    					queue.offer(new Node(childId,node));
    				}
    			}
    		}
    
    		return null;
    	}
    	
    	/**
    	 * 节点对象
    	 * @author Administrator
    	 *
    	 */
    	static class Node{
    		//节点唯一id
    		public String id;
    		//该节点的直接父节点
    		public Node parent;
    		//该节点的直接子节点
    		public List<Node> childs = new ArrayList<Node>();
    		public Node(String id,Node parent) {
    			this.id = id;
    			this.parent = parent;
    		}
    	}
    
    }
```



---

# 工具资源

1） 原生代码实现：

　　a) URL类

2） 使用第三方的URL库

　　a) HttpClient库

3） 开源爬虫框架

　　a) Heritrix

　　b) Nutch